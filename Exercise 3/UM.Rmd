---
title: "UM"
author: "Stanisław Wasik"
date: "25.11.2020"
output: md_document 
#output: html_document
---

## Załaduj zbiór danych churn:
```{r, cache=TRUE}
library(modeldata)
library(dplyr)
data(mlc_churn)
churnData <- data.frame(mlc_churn)

library(caret)
set.seed(42)
```

## Podziel ten zbiór na uczący i testowy (75% w zbiorze uczącym)
```{r, cache=TRUE}
inTraining <-
    createDataPartition(
        y = churnData$churn,
        p = .75,
        list = FALSE)

training <- churnData[ inTraining,]
testing  <- churnData[-inTraining,]
```

## Przetestuj dwa algorytmy klasyfikacyjne
```{r, cache=TRUE}
ctrl <- trainControl(method = "none")
fit <- train(churn ~ ., data = training, method = "rf", trControl = ctrl, preProc = c("center", "scale"), ntree = 10)
fit
confusionMatrix(data = predict(fit, newdata = testing), testing$churn)
```

```{r, cache=TRUE}
fit2 <- train(churn ~ ., data = training, method = "knn", trControl = ctrl)
fit2
confusionMatrix(data = predict(fit2, newdata = testing), testing$churn)
```

## Zastanów się czy warto wstępnie przetworzyć zbiór
Wstępne przetwarzanie zbioru nie zawsze jest dobrym rozwiązaniem, może to naruszyć strukturę danych. Jednakże przetwarzanie danych wskazane jest np. przy kNN czy sieciach neuronowych.

## Określ przestrzeń przeszukiwania parametrów

```{r train, cache=TRUE}

gridCtrl <- trainControl(
    method = "cv",
    summaryFunction = twoClassSummary,
    classProbs = TRUE)

rfGrid1 <- expand.grid(mtry = 1:5)
fitTune <- train(churn ~ .,
             data = training,
             method = "rf",
             metric = "ROC",
             trControl = gridCtrl,
             tuneGrid = rfGrid1)
```

```{r, cache=TRUE}

rfGrid2 <- expand.grid(k = c(1,2,3,4,5))
fitTune2 <- train(churn ~ .,
             data = training,
             method = "knn",
             metric = "ROC",
             preProc = c("center", "scale"),
             trControl = gridCtrl,
             tuneGrid = rfGrid2)
```

## Porównaj algorytmy za pomocą wykresu
```{r, cache=TRUE}
resamps <- resamples(list(rf = fitTune, knn = fitTune2))

theme1 <- trellis.par.get()
theme1$plot.symbol$col = rgb(.2, .2, .2, .4)
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(1, 0, 0, .7)
theme1$plot.line$lwd <- 2

trellis.par.set(theme1)
bwplot(difValues, layout = c(3, 1))
```

## Załaduj zbiór diamonds:
```{r, cache=TRUE}
library(ggplot2)

data <- data.frame(diamonds)
```


## Podziel zbiór na uczący i testowy w proporcjach 70%-30%
```{r, cache=TRUE}
inTraining <-
    createDataPartition(
        y = data$price,
        p = .70,
        list = FALSE)

training <- data[ inTraining,]
testing  <- data[-inTraining,]
```


## Stwórz model regresyjny, który przewidzi cenę diamentu na podstawie wartości pozostałych parametrów
```{r, cache=TRUE}
ctrl <- trainControl(method = "none")
model <- train(price ~ ., data = training, method = "lm", trControl = ctrl)

predicted = predict(model, newdata=select(testing, -c(price)))
gt = testing$price
MAE(predicted, gt)

```


## W trakcie pracy przypatrz się wpływowi różnych zmiennych na cenę diamentu
```{r, cache=TRUE}
library(dplyr)
data <- sample_n(diamonds, 250)
featurePlot(x = data[,c("x","y","z","carat","depth","table")],
            y = data$price, 
            plot = "scatter",
            auto.key = list(columns = 3))
```

